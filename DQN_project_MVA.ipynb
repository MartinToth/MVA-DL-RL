{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG0eNgfvfY4i",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxTvd4IlfY4m",
        "colab_type": "code",
        "outputId": "2703256b-ce41-4f15-cbfc-c1293c127113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "## install dependencies for google colab\n",
        "!pip install scikit-video\n",
        "!pip install opencv-python\n",
        "\n",
        "## check that GPU is enabled for keras\n",
        "import tensorflow as tf\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko0zodCKfyZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense,Flatten\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWQfHL98fY4t",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXA4J6hGfY4v",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hciQ6alTfY4x",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtwGbRHVfY4y",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRJI4aCffY4y",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXRdZVgvfY4z",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt-79uCafY40",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiNyhlqcfY6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VFeuDEkfY6E",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceJ5iqByfY6F",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZWDEiH8fY6H",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHqNNpOjfY6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        return\n",
        "        \n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFHg4W-hfY6M",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkbUV3FLfY6N",
        "colab_type": "text"
      },
      "source": [
        "# Answer 1\n",
        "\n",
        "In the function act, we either :\n",
        "- sample the action $a_t$ under our given policy with probability $1-\\epsilon$\n",
        "- chose a random action $a_t$ with probability $\\epsilon$\n",
        "\n",
        "The goal of this method is to ensure that the Agent will continue to explore the environment through the whole training whatever policy training method we chose. Thus the choice of $\\epsilon$ is essential. It will dictate how likely the Agent will follow the training method we implement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4AG6XAIfY6O",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZMYnRvMfY6Q",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXRCBPO9fY6R",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGcoRJ2LfY6S",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr8m6i4DfY6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        # I changed the colors to get green for bonuses and red for maluses\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,1] = 256\n",
        "        b[self.board < 0, 0] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "    #adding a variable train for the following questions\n",
        "    def act(self, action,training='False'):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBMOftwKfY6a",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh22k9lhfY6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=10 # set small when debugging\n",
        "epochs_test=5 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKMuu_SofY6f",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q-2gkssfY6g",
        "colab_type": "text"
      },
      "source": [
        "# Answer 2\n",
        "Both are 2 dimensional arrays of size (grid_size+4,grid_size+4). The padding is here to send the visualisation information of 25 cells even if we are near a border. We can always see 2 cases ahead (they might be blank).\n",
        "\n",
        "- The array board contains informations about the bonus / malus available. It is a two dimensional matrix where board[i,j] indicates the values of the bonus/malus. At building time, the cell has no value. Then a realisation of a bernoulli distribution of parameter *temperature* decides if it will have a malus. Another realisation of the same distribution decides it if will have a bonus (eventually replacing the malus).\n",
        "\n",
        "- The array position contains our position on the map. It is used to show the 25 cells seeable by the Agent without problem when he is near a border."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbSkRzONfY6h",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kkIeXdlfY6i",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwgEn0XDfY6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXayXHGBfY6v",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qivzLoA6fY6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state,train='False')\n",
        "            \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action,training='False')\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            \n",
        "        \n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))\n",
        "    ## adding a return statement to get the final score\n",
        "    return score/epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY82fFT1fY60",
        "colab_type": "code",
        "outputId": "5b784601-d89d-43f6-d4f9-98aca77ac0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 9.0/17.0. Average score (-8.0)\n",
            "Win/lose count 11.5/9.0. Average score (-2.75)\n",
            "Win/lose count 12.5/14.0. Average score (-2.3333333333333335)\n",
            "Win/lose count 12.5/17.0. Average score (-2.875)\n",
            "Win/lose count 9.0/11.0. Average score (-2.7)\n",
            "Final score: -2.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-mx1zA9fY6_",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3hxrslMfY7A",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a}Q(s',a,\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fdtox2HfY7B",
        "colab_type": "text"
      },
      "source": [
        "## Answer 5 :\n",
        "By definition :\n",
        "$$ Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t=0}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] $$\n",
        "\n",
        "$$ Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t \\geq 1}\\gamma^{t}r(s_{t},a_{t}) + r(s_0,a_0)|s_{0}=s,a_{0}=a] $$\n",
        "\n",
        "$$ Q^\\pi(s,a)=E_{p^{\\pi}}[\\gamma\\sum_{t \\geq 1}\\gamma^{t-1}r(s_{t},a_{t}) + r(s_0,a_0)|s_{0}=s,a_{0}=a] $$\n",
        "\n",
        "$$ Q^\\pi(s,a) = r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t \\geq 0}\\gamma^{t}r(s_{t+1},a_{t+1}) |s_{0}=s,a_{0}=a]   $$\n",
        "\n",
        "with\n",
        "$$\n",
        "E_{p^{\\pi}}[\\sum_{t \\geq 0}\\gamma^{t}r(s_{t+1},a_{t+1}) |s_{0}=s,a_{0}=a] = \\sum_{a',s'} P^{\\pi}(s_1 = s',a_1 = a') E_{p^{\\pi}}[\\sum_{t \\geq 0}\\gamma^{t}r(s_{t+1},a_{t+1}) |s_{1}=s',a_{1}=a'] =\n",
        "\\sum_{a',s'} P^{\\pi}(s_1 = s',a_1 = a')Q^{\\pi}(s';a')\n",
        "$$\n",
        "\n",
        "So \n",
        "$$Q^{\\pi}(s,a)=E_{(s',a')\\sim p^{\\pi}(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')] $$.\n",
        "\n",
        "For the optimal policy : \n",
        "$$Q^{\\pi^*}(s,a)= \\underset{\\pi}{max} \\;Q^{\\pi}(s,a) = \\underset{\\pi}{max} \\; E_{(s',a')\\sim \\pi(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')] $$\n",
        "\n",
        "To maximize with respect to the policy we have to chose the best action :\n",
        "\n",
        "$$\n",
        "Q^{\\pi^*}(s,a) = \\underset{\\pi, a' }{max} \\; E_{(s')\\sim \\pi(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')] \n",
        "$$\n",
        "$$\n",
        " Q^{\\pi^*}(s,a) = \\underset{\\pi }{max} \\; E_{(s')\\sim \\pi(.|s,a)}[r(s,a)+\\gamma \\underset{a'}{max} \\; Q^{\\pi}(s',a')]\n",
        "$$\n",
        "$$\n",
        " Q^{\\pi^*}(s,a) =  E_{(s')\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma \\underset{a'}{max} \\; Q^{\\pi^*}(s',a')]\n",
        "$$\n",
        "\n",
        "\n",
        "We showed that the optimal Q function is the fixed point of the optimal Bellman operator. Thus it is a good choice of loss to reduce the difference between the two terms : $Q^{\\pi}(s,a,\\theta)$ and $E_{s' \\sim \\pi^*(.|s,a)} [ r+\\gamma\\max_{a}Q^{\\pi}(s',a,\\theta)]$. If we chose the L2 norm we get $$\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a}Q(s',a,\\theta)-Q(s,a,\\theta)\\Vert^{2}. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r81WysW3fY7C",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2n8LKH2fY7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "        self.position = 0\n",
        "\n",
        "    def remember(self, m):\n",
        "        #we append the move if the memory is not full\n",
        "        if len(self.memory) < self.max_memory : \n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = m\n",
        "        self.position = (self.position +1 )% self.max_memory\n",
        "\n",
        "    def random_access(self):\n",
        "        if len(self.memory) == 1:\n",
        "            return self.memory[0]\n",
        "        else:\n",
        "            return self.memory[np.random.randint(0,len(self.memory)-1)]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZcucMwofY7H",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfY4kA_RfY7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptbFc4tRfY7L",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q6wVeLrfY7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        actions_returns = self.model.predict(np.expand_dims(s,0))\n",
        "        return np.argmax(actions_returns)\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            ## first we get a sample\n",
        "            s, n_s , a , r , game_over_ = self.memory.random_access()\n",
        "            input_states[i] = s\n",
        "            target_q[i] = self.model.predict(np.expand_dims(s,0))\n",
        "            if game_over_:\n",
        "                target_q[i][a] = r\n",
        "            else:\n",
        "                target_q[i][a] = r + self.discount*np.amax(self.model.predict(np.expand_dims(n_s,0)))\n",
        "                \n",
        "        \n",
        "        \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential([\n",
        "        Flatten(),\n",
        "        Dense(128, input_shape=(50,)),\n",
        "        Activation('relu'),\n",
        "        Dense(256),\n",
        "        Activation('relu'),\n",
        "        Dense(4),\n",
        "        Activation('relu'),\n",
        "                ])\n",
        "        \n",
        "\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "    #for the last question\n",
        "    # e is the epoch\n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = self.epsilon *(e-1) /e\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAsrwshsfY7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LJSyHGFfY7k",
        "colab_type": "code",
        "outputId": "a953f260-ca13-4039-c26a-f62fc4ac367b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train0.mp4'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/010 | Loss 0.0835 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 001/010 | Loss 0.0551 | Win/lose count 1.5/2.0 (-0.5)\n",
            "Epoch 002/010 | Loss 0.0022 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 003/010 | Loss 0.1141 | Win/lose count 2.0/7.0 (-5.0)\n",
            "Epoch 004/010 | Loss 0.0014 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 005/010 | Loss 0.0416 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 006/010 | Loss 0.0396 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 007/010 | Loss 0.0554 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 008/010 | Loss 0.0048 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 009/010 | Loss 0.0025 | Win/lose count 1.5/1.0 (0.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wNFYPglfY7p",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BLS8kfWfY7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(8,(2,2)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(32,(2,2)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkGjy0DofY7v",
        "colab_type": "code",
        "outputId": "2ab57015-95cc-4872-e9b4-2ecea68a1baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train0.mp4'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/010 | Loss 0.0011 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 001/010 | Loss 0.0137 | Win/lose count 0/7.0 (-7.0)\n",
            "Epoch 002/010 | Loss 0.0059 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 003/010 | Loss 0.0035 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 004/010 | Loss 0.0140 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 005/010 | Loss 0.0019 | Win/lose count 8.0/3.0 (5.0)\n",
            "Epoch 006/010 | Loss 0.0082 | Win/lose count 1.5/2.0 (-0.5)\n",
            "Epoch 007/010 | Loss 0.0037 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 008/010 | Loss 0.0147 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 009/010 | Loss 0.0453 | Win/lose count 2.0/1.0 (1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajRHRuiFfY7y",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm7N8xNffY7z",
        "colab_type": "code",
        "outputId": "8f6ab9d3-2ddc-4ae9-8cd3-f51e88c99415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 4.0/5.0. Average score (-1.0)\n",
            "Win/lose count 3.5/4.0. Average score (-0.75)\n",
            "Win/lose count 1.5/1.0. Average score (-0.3333333333333333)\n",
            "Win/lose count 5.0/3.0. Average score (0.25)\n",
            "Win/lose count 2.5/6.0. Average score (-0.5)\n",
            "Final score: -0.5\n",
            "Test of the FC\n",
            "Win/lose count 3.0/2.0. Average score (1.0)\n",
            "Win/lose count 2.0/2.0. Average score (0.5)\n",
            "Win/lose count 5.5/2.0. Average score (1.5)\n",
            "Win/lose count 3.5/6.0. Average score (0.5)\n",
            "Win/lose count 4.0/2.0. Average score (0.8)\n",
            "Final score: 0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5hYkhLtfY76",
        "colab_type": "code",
        "outputId": "fec85873-7153-4cb1-9800-d6dcf9e26c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "temp_values = np.linspace(0.2,1,5)\n",
        "final_scores_FC = []\n",
        "final_scores_CNN = []\n",
        "epochs_test = 5\n",
        "epochs_train = 10\n",
        "for temp in tqdm.tqdm(temp_values):\n",
        "    env = Environment(grid_size=size, max_time=T,temperature=temp)\n",
        "    agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "    agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "    train(agent_cnn,env,epochs_train,prefix='cnn_train_'+str(temp))\n",
        "    train(agent_fc,env,epochs_train,prefix='fc_train_'+str(temp))\n",
        "    final_scores_FC.append(test(agent_fc,env,epochs_test,prefix='fc_test_'+str(temp)))\n",
        "    final_scores_CNN.append(test(agent_cnn,env,epochs_test,prefix='cnn_test_'+str(temp)))\n",
        "    \n",
        "    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/010 | Loss 0.0020 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 001/010 | Loss 0.0003 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 002/010 | Loss 0.0006 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 003/010 | Loss 0.0103 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 004/010 | Loss 0.0150 | Win/lose count 0.5/0 (0.5)\n",
            "Epoch 005/010 | Loss 0.0149 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 006/010 | Loss 0.0032 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 007/010 | Loss 0.0094 | Win/lose count 0.5/0 (0.5)\n",
            "Epoch 008/010 | Loss 0.0083 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 009/010 | Loss 0.0074 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 000/010 | Loss 0.0081 | Win/lose count 1.5/5.0 (-3.5)\n",
            "Epoch 001/010 | Loss 0.0021 | Win/lose count 0.5/3.0 (-2.5)\n",
            "Epoch 002/010 | Loss 0.0046 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 003/010 | Loss 0.0066 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 004/010 | Loss 0.0064 | Win/lose count 1.0/2.0 (-1.0)\n",
            "Epoch 005/010 | Loss 0.0070 | Win/lose count 1.5/0 (1.5)\n",
            "Epoch 006/010 | Loss 0.0053 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 007/010 | Loss 0.0050 | Win/lose count 0/0 (0)\n",
            "Epoch 008/010 | Loss 0.0059 | Win/lose count 1.5/0 (1.5)\n",
            "Epoch 009/010 | Loss 0.0059 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Win/lose count 1.5/0. Average score (1.5)\n",
            "Win/lose count 3.0/1.0. Average score (1.75)\n",
            "Win/lose count 1.5/1.0. Average score (1.3333333333333333)\n",
            "Win/lose count 1.5/5.0. Average score (0.125)\n",
            "Win/lose count 1.5/0. Average score (0.4)\n",
            "Final score: 0.4\n",
            "Win/lose count 2.0/0. Average score (2.0)\n",
            "Win/lose count 3.0/1.0. Average score (2.0)\n",
            "Win/lose count 3.0/1.0. Average score (2.0)\n",
            "Win/lose count 6.5/2.0. Average score (2.625)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [02:43<10:54, 163.59s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 3.5/2.0. Average score (2.4)\n",
            "Final score: 2.4\n",
            "Epoch 000/010 | Loss 0.0035 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 001/010 | Loss 0.0024 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 002/010 | Loss 0.0166 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 003/010 | Loss 0.0068 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 004/010 | Loss 0.0062 | Win/lose count 4.0/9.0 (-5.0)\n",
            "Epoch 005/010 | Loss 0.0061 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 006/010 | Loss 0.0097 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 007/010 | Loss 0.0069 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 008/010 | Loss 0.0147 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 009/010 | Loss 0.0480 | Win/lose count 6.0/0 (6.0)\n",
            "Epoch 000/010 | Loss 0.0030 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 001/010 | Loss 0.0135 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 002/010 | Loss 0.0051 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 003/010 | Loss 0.0369 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 004/010 | Loss 0.0112 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 005/010 | Loss 0.0092 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 006/010 | Loss 0.0127 | Win/lose count 3.5/6.0 (-2.5)\n",
            "Epoch 007/010 | Loss 0.0521 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 008/010 | Loss 0.0072 | Win/lose count 5.5/8.0 (-2.5)\n",
            "Epoch 009/010 | Loss 0.0161 | Win/lose count 4.0/3.0 (1.0)\n",
            "Win/lose count 4.0/3.0. Average score (1.0)\n",
            "Win/lose count 2.0/2.0. Average score (0.5)\n",
            "Win/lose count 4.0/1.0. Average score (1.3333333333333333)\n",
            "Win/lose count 1.5/2.0. Average score (0.875)\n",
            "Win/lose count 7.0/2.0. Average score (1.7)\n",
            "Final score: 1.7\n",
            "Win/lose count 5.5/3.0. Average score (2.5)\n",
            "Win/lose count 7.5/4.0. Average score (3.0)\n",
            "Win/lose count 8.5/1.0. Average score (4.5)\n",
            "Win/lose count 5.0/1.0. Average score (4.375)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [05:28<08:11, 163.94s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.5/2.0. Average score (5.4)\n",
            "Final score: 5.4\n",
            "Epoch 000/010 | Loss 0.0168 | Win/lose count 4.0/5.0 (-1.0)\n",
            "Epoch 001/010 | Loss 0.0108 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 002/010 | Loss 0.0194 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 003/010 | Loss 0.1245 | Win/lose count 7.5/10.0 (-2.5)\n",
            "Epoch 004/010 | Loss 0.0145 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 005/010 | Loss 0.0079 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 006/010 | Loss 0.0548 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 007/010 | Loss 0.1154 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 008/010 | Loss 0.0516 | Win/lose count 10.0/2.0 (8.0)\n",
            "Epoch 009/010 | Loss 0.0628 | Win/lose count 9.0/1.0 (8.0)\n",
            "Epoch 000/010 | Loss 0.0041 | Win/lose count 3.5/7.0 (-3.5)\n",
            "Epoch 001/010 | Loss 0.0100 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 002/010 | Loss 0.0239 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 003/010 | Loss 0.0297 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 004/010 | Loss 0.0200 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 005/010 | Loss 0.0040 | Win/lose count 5.5/1.0 (4.5)\n",
            "Epoch 006/010 | Loss 0.0350 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 007/010 | Loss 0.0239 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 008/010 | Loss 0.0157 | Win/lose count 7.5/7.0 (0.5)\n",
            "Epoch 009/010 | Loss 0.0102 | Win/lose count 3.5/3.0 (0.5)\n",
            "Win/lose count 2.5/3.0. Average score (-0.5)\n",
            "Win/lose count 4.0/4.0. Average score (-0.25)\n",
            "Win/lose count 4.5/3.0. Average score (0.3333333333333333)\n",
            "Win/lose count 4.5/3.0. Average score (0.625)\n",
            "Win/lose count 3.0/7.0. Average score (-0.3)\n",
            "Final score: -0.3\n",
            "Win/lose count 11.0/3.0. Average score (8.0)\n",
            "Win/lose count 11.5/7.0. Average score (6.25)\n",
            "Win/lose count 5.5/1.0. Average score (5.666666666666667)\n",
            "Win/lose count 4.0/0. Average score (5.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [08:12<05:28, 164.02s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 6.0/3.0. Average score (4.8)\n",
            "Final score: 4.8\n",
            "Epoch 000/010 | Loss 0.0133 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 001/010 | Loss 0.0036 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 002/010 | Loss 0.0028 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 003/010 | Loss 0.0655 | Win/lose count 18.5/5.0 (13.5)\n",
            "Epoch 004/010 | Loss 0.0112 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 005/010 | Loss 0.0081 | Win/lose count 18.5/3.0 (15.5)\n",
            "Epoch 006/010 | Loss 0.0484 | Win/lose count 9.5/2.0 (7.5)\n",
            "Epoch 007/010 | Loss 0.0043 | Win/lose count 17.5/2.0 (15.5)\n",
            "Epoch 008/010 | Loss 0.0030 | Win/lose count 14.5/2.0 (12.5)\n",
            "Epoch 009/010 | Loss 0.0070 | Win/lose count 18.0/3.0 (15.0)\n",
            "Epoch 000/010 | Loss 0.0042 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 001/010 | Loss 0.0158 | Win/lose count 7.5/3.0 (4.5)\n",
            "Epoch 002/010 | Loss 0.0500 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 003/010 | Loss 0.0738 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 004/010 | Loss 0.1063 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 005/010 | Loss 0.1201 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 006/010 | Loss 0.0367 | Win/lose count 15.0/1.0 (14.0)\n",
            "Epoch 007/010 | Loss 0.1296 | Win/lose count 15.0/3.0 (12.0)\n",
            "Epoch 008/010 | Loss 0.0633 | Win/lose count 22.0/4.0 (18.0)\n",
            "Epoch 009/010 | Loss 0.1094 | Win/lose count 10.0/3.0 (7.0)\n",
            "Win/lose count 8.5/1.0. Average score (7.5)\n",
            "Win/lose count 5.0/4.0. Average score (4.25)\n",
            "Win/lose count 4.5/0. Average score (4.333333333333333)\n",
            "Win/lose count 16.5/3.0. Average score (6.625)\n",
            "Win/lose count 13.0/0. Average score (7.9)\n",
            "Final score: 7.9\n",
            "Win/lose count 6.0/1.0. Average score (5.0)\n",
            "Win/lose count 17.0/0. Average score (11.0)\n",
            "Win/lose count 10.5/1.0. Average score (10.5)\n",
            "Win/lose count 18.5/2.0. Average score (12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [10:58<02:44, 164.69s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 7.5/2.0. Average score (10.7)\n",
            "Final score: 10.7\n",
            "Epoch 000/010 | Loss 0.0049 | Win/lose count 10.5/0 (10.5)\n",
            "Epoch 001/010 | Loss 0.0051 | Win/lose count 18.5/0 (18.5)\n",
            "Epoch 002/010 | Loss 0.0020 | Win/lose count 13.5/0 (13.5)\n",
            "Epoch 003/010 | Loss 0.0664 | Win/lose count 15.5/0 (15.5)\n",
            "Epoch 004/010 | Loss 0.0071 | Win/lose count 17.5/0 (17.5)\n",
            "Epoch 005/010 | Loss 0.0053 | Win/lose count 24.5/0 (24.5)\n",
            "Epoch 006/010 | Loss 0.0025 | Win/lose count 27.5/0 (27.5)\n",
            "Epoch 007/010 | Loss 0.0028 | Win/lose count 24.5/0 (24.5)\n",
            "Epoch 008/010 | Loss 0.0072 | Win/lose count 30.0/0 (30.0)\n",
            "Epoch 009/010 | Loss 0.0056 | Win/lose count 31.5/0 (31.5)\n",
            "Epoch 000/010 | Loss 0.0011 | Win/lose count 10.0/0 (10.0)\n",
            "Epoch 001/010 | Loss 0.0058 | Win/lose count 19.5/0 (19.5)\n",
            "Epoch 002/010 | Loss 0.0046 | Win/lose count 17.5/0 (17.5)\n",
            "Epoch 003/010 | Loss 0.0515 | Win/lose count 13.0/0 (13.0)\n",
            "Epoch 004/010 | Loss 0.0072 | Win/lose count 16.0/0 (16.0)\n",
            "Epoch 005/010 | Loss 0.0397 | Win/lose count 18.5/0 (18.5)\n",
            "Epoch 006/010 | Loss 0.0031 | Win/lose count 18.0/0 (18.0)\n",
            "Epoch 007/010 | Loss 0.0054 | Win/lose count 23.0/0 (23.0)\n",
            "Epoch 008/010 | Loss 0.0024 | Win/lose count 16.0/0 (16.0)\n",
            "Epoch 009/010 | Loss 0.0529 | Win/lose count 19.5/0 (19.5)\n",
            "Win/lose count 10.0/0. Average score (10.0)\n",
            "Win/lose count 16.5/0. Average score (13.25)\n",
            "Win/lose count 10.0/0. Average score (12.166666666666666)\n",
            "Win/lose count 23.5/0. Average score (15.0)\n",
            "Win/lose count 9.5/0. Average score (13.9)\n",
            "Final score: 13.9\n",
            "Win/lose count 33.0/0. Average score (33.0)\n",
            "Win/lose count 32.5/0. Average score (32.75)\n",
            "Win/lose count 30.0/0. Average score (31.833333333333332)\n",
            "Win/lose count 30.5/0. Average score (31.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [13:44<00:00, 165.13s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 19.5/0. Average score (29.1)\n",
            "Final score: 29.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sll_9y2PfY78",
        "colab_type": "code",
        "outputId": "7b724785-5ae0-458e-802c-1968f2535198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title(\"Average score function of temperature\")\n",
        "plt.xlabel(\"temperature\")\n",
        "plt.ylabel(\"final score\")\n",
        "plt.plot(temp_values,final_scores_FC,'r^',label='Fully connected')\n",
        "plt.plot(temp_values,final_scores_CNN,'b+',label='Convolutionnal')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNau7KYQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6jRwvBRfY7-",
        "colab_type": "code",
        "outputId": "4d7a3810-3c46-4b0c-968f-19aa4bfe5d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "HTML(display_videos('cnn_test_1.00.mp4'))\n",
        "##temperature = 1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ypnbhl5515q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "fc3dd6b1-5919-48d1-be59-330779a5117a"
      },
      "source": [
        "HTML(display_videos('cnn_test_0.40.mp4'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOm9z5qofY8B",
        "colab_type": "code",
        "outputId": "e0f9f32d-beda-4c63-c37a-04bd0b32936e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "\n",
        "HTML(display_videos('fc_test_0.40.mp4'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb3jHx9-fY8J",
        "colab_type": "text"
      },
      "source": [
        "# Answer 9\n",
        "\n",
        "- First we can clearly see that the mouse is not exploring enough. Both CNN and FC networks are stay at the same places.\n",
        "- Secondly we can observe better performance for CNN, it is in adequation with the fact that it is a network adapted to pictural inputs which is the case in our example. We want the network to learn to spot the \"good\" cases and to learn to act toward them\n",
        "- The temperature is the probability that a case get a malus or bonus. Given the fact that a bonus erase the malus on the same case, it is obvious that the higher the temperature, the higher the score (when temperature = 1 all the cases have a bonus). However it is not obvious which type of environment will ease the learning phase. Temperature around 0.4 offers a good trade-off between not enough bonus / malus and too much bonus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjEHSD2gfY8K",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98jm62EfY8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    pass\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        pass\n",
        "    \n",
        "## use those samples of code:\n",
        "#In train explore:\n",
        "state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "## In Environment exploring:\n",
        "# You will have to change n_state to 3 because you will use one more layer!\n",
        "reward = 0\n",
        "if train:\n",
        "    reward = -self.malus_position[self.x, self.y]\n",
        "self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "reward = reward + self.board[self.x, self.y]\n",
        "# 3 \"feature\" states instead of 2\n",
        "state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ3mq7swkkxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## The function train_explore has 2 mains differences :\n",
        "## 1. For each epoch we change the epsilon-greedy value of the agent\n",
        "## 2. the environment will \n",
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        ### Adding a change in the epsilon\n",
        "        ### each epochs e is played with epsilon_e = espilon_0 / e\n",
        "        if e+1 > 1:\n",
        "            agent.set_epsilon(e+1)\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action,training=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MboxAWUDplnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnvironmentExploring(Environment):\n",
        "      def __init__(self,grid_size=10,max_time=500,temperature=0.1):\n",
        "          super(EnvironmentExploring,self).__init__(grid_size,max_time,temperature)\n",
        "\n",
        "          self.malus_position = np.zeros((grid_size,grid_size))\n",
        "  \n",
        "      def reset(self):\n",
        "          \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "          self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "          self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "          bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "          bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "          malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "          malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "          self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "          malus[bonus>0]=0\n",
        "\n",
        "          self.board = bonus + malus\n",
        "\n",
        "          self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "          self.position[0:2,:]= -1\n",
        "          self.position[:,0:2] = -1\n",
        "          self.position[-2:, :] = -1\n",
        "          self.position[-2:, :] = -1\n",
        "          self.board[self.x,self.y] = 0\n",
        "          self.t = 0\n",
        "\n",
        "          #malus_position tracks the malus associated with each position, it starts at 0\n",
        "          self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "          self.malus_position[0:2,:]= -1\n",
        "          self.malus_position[:,0:2] = -1\n",
        "          self.malus_position[-2:, :] = -1\n",
        "          self.malus_position[-2:, :] = -1\n",
        "\n",
        "          state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                          self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "          state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "          return state\n",
        "\n",
        "      def act(self, action,training=False):\n",
        "          \"\"\"This function returns the new state, reward and decides if the\n",
        "          game ends.\"\"\"\n",
        "\n",
        "          self.get_frame(int(self.t))\n",
        "\n",
        "          self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "          self.position[0:2,:]= -1\n",
        "          self.position[:,0:2] = -1\n",
        "          self.position[-2:, :] = -1\n",
        "          self.position[-2:, :] = -1\n",
        "\n",
        "          self.position[self.x, self.y] = 1\n",
        "          if action == 0:\n",
        "              if self.x == self.grid_size-3:\n",
        "                  self.x = self.x-1\n",
        "              else:\n",
        "                  self.x = self.x + 1\n",
        "          elif action == 1:\n",
        "              if self.x == 2:\n",
        "                  self.x = self.x+1\n",
        "              else:\n",
        "                  self.x = self.x-1\n",
        "          elif action == 2:\n",
        "              if self.y == self.grid_size - 3:\n",
        "                  self.y = self.y - 1\n",
        "              else:\n",
        "                  self.y = self.y + 1\n",
        "          elif action == 3:\n",
        "              if self.y == 2:\n",
        "                  self.y = self.y + 1\n",
        "              else:\n",
        "                  self.y = self.y - 1\n",
        "          else:\n",
        "              RuntimeError('Error: action not recognized')\n",
        "\n",
        "          self.t = self.t + 1\n",
        "\n",
        "          #changes are here\n",
        "          reward = 0\n",
        "          if training == True:\n",
        "            reward -= self.malus_position[self.x,self.y]\n",
        "          #we update the malus_position\n",
        "          #if never visited we add -0.2\n",
        "          #else we add 10% until it reaches 0.6\n",
        "          if self.malus_position[self.x, self.y] < 0.2:\n",
        "              self.malus_position[self.x,self.y] = 0.2\n",
        "          elif self.malus_position[self.x, self.y] < 0.6:\n",
        "              self.malus_position[self.x, self.y] = self.malus_position[self.x, self.y] *1.1\n",
        "          \n",
        "\n",
        "          reward += self.board[self.x, self.y]\n",
        "          self.board[self.x, self.y] = 0\n",
        "          game_over = self.t > self.max_time\n",
        "          state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                          self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                          self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "          state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "          return state, reward, game_over\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhyFGhqofY8y",
        "colab_type": "code",
        "outputId": "4d213fba-5ee0-4462-f83f-0f5e64fffe1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Training\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=15 # set small when debugging\n",
        "epochs_test=5\n",
        "\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.3, memory_size=2000, batch_size = 16,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/015 | Loss 0.0209 | Win/lose count 12.5/53.036654905736604 (-40.536654905736604)\n",
            "Epoch 001/015 | Loss 0.0336 | Win/lose count 12.0/43.86830944157239 (-31.868309441572393)\n",
            "Epoch 002/015 | Loss 0.0128 | Win/lose count 16.5/45.402203365707216 (-28.902203365707216)\n",
            "Epoch 003/015 | Loss 0.0213 | Win/lose count 13.0/35.352821999999975 (-22.352821999999975)\n",
            "Epoch 004/015 | Loss 0.0594 | Win/lose count 14.0/34.62717143999997 (-20.62717143999997)\n",
            "Epoch 005/015 | Loss 0.0332 | Win/lose count 11.5/42.38510352688399 (-30.885103526883988)\n",
            "Epoch 006/015 | Loss 0.0398 | Win/lose count 24.5/21.587999999999976 (2.912000000000024)\n",
            "Epoch 007/015 | Loss 0.1374 | Win/lose count 20.5/28.61761999999998 (-8.117619999999981)\n",
            "Epoch 008/015 | Loss 0.0118 | Win/lose count 20.5/30.215521999999968 (-9.715521999999968)\n",
            "Epoch 009/015 | Loss 0.0354 | Win/lose count 17.5/36.84388682443998 (-19.343886824439977)\n",
            "Epoch 010/015 | Loss 0.0224 | Win/lose count 23.5/27.17509961999999 (-3.6750996199999904)\n",
            "Epoch 011/015 | Loss 0.0084 | Win/lose count 15.5/39.30468021999999 (-23.804680219999987)\n",
            "Epoch 012/015 | Loss 0.0247 | Win/lose count 20.0/31.148399999999967 (-11.148399999999967)\n",
            "Epoch 013/015 | Loss 0.0160 | Win/lose count 17.5/37.63258199999998 (-20.132581999999978)\n",
            "Epoch 014/015 | Loss 0.0229 | Win/lose count 18.5/33.84683999999996 (-15.346839999999958)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt4UpEKTCRIZ",
        "colab_type": "code",
        "outputId": "4d9367a7-06db-489b-98b3-c1e4dd863e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "HTML(display_videos('cnn_train_explore0.mp4'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGH5tZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAMTZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpHZJ3iTdwgGIkEo+BTF5uvgUzGtW17PO2SM5vxEmLD40duCpcDb1oy/FEULklIyihYUcapthtVuSSBN1wGz2F3qmbYrQ8Axgd5rSmc0Q7XLkQAh71kwwPK3alg7sgDENTOYyAYxWbdZOiHhG7Sh1FGyqhd1+auYc5OLdgmWhoK68rESsisqGOv9OpKr7MaSbVXE4zJkVlARRbW4u/upa681FD88izEuVAaEkEeAeJSpvF0VBt7cNcD5FyZ4XJ5lvOAXdPtFmsgE8KdEErXkEqNiEh7dReNV6zvG3JOZuAp9P60gaPUYyIBwY7JQLVOO7eGsLUqQi2GXkmOcJ8RzVYS6l0aefSaYTsEpsoR/QEAw8rMgNjF6LcFm/EfynoJ4N6ROSslAscvtB1P9a3hxloEmaUhYUB61/bn9d1A3zZQWInpgdSb1Mh7CzUL/HeVtBo0EbbZMDxuJc6O+erLGxicLqe5RDYf1ysRiBAPsvZqJp+tPn+bkPyn0KV6pzQyZhZRuO2i0vxK5r6yMoLKvWS51jmnfRKaWHBl1KyX7TKLZ/zgmDB30K7Xm5C/VZi3AJhSE2Gyry0d/XoURKKs9+1/kRHtiMXENB5pvPjeSc9U1r9+5Y0LBcKchw8cXPZvX2UUB+KvcRpDXaLgAA/JOIep8rT0C6iawqe6sxXHO61i4mhm6fVZSKNsl2SgcG5ylhTt3xCnC+DLR3bTf0EbkzYkvQICuQnNDHmo0HxhuIDkqVEu4F8etADQSYt4UUBaCD26bLSdfdAUY8YGsV9pRhL3xipgyU5hwHr6WKl6Onf+lkyS935Kgl1maNTdEWq1TXSJFycbM28pj5lF5bi1B+T+gZqvlJ8cI6ExOdz9rcEoNQemfaLc9ByPyBu0hoosUtMjq5iQHFCnlonH/tCPgJ/e2EGvVkXBBpM0txIbZjCjI0NUZSDHyFnThhIFyBwsgRFZy04QAjgALaQAAABhBmiNsQz/+nhAD4ervzLK8To4n7XRqnWwAAAAQQZ5BeIV/ANLJnAGN52VDBQAAABABnmJqQr8A0rqnkwPXtsWAAAAAGkGaZEmoQWiZTAhv//6nhAD9+wf4U+0gpL0hAAAAGUGahUnhClJlMCG//qeEAKh7qfqONCQ4UEEAAAAeQZqpSeEOiZTAhv/+p4QArAA1ILn4n//On1qNLRbdAAAAFUGex0URPC//AGcVak2VHjp1x+UmfQAAABABnuZ0Qr8AWJOpPK/JTaJwAAAAEAGe6GpCvwCK7PHK/tw+r0AAAAAaQZrqSahBaJlMCG///qeEAKz7qfqONCQ4TcEAAAAbQZsNSeEKUmUwIb/+p4QAcQHhTrRwCa/0a2BAAAAAEEGfK0U0TCv/AF0sK9idKAQAAAAOAZ9MakK/AF0sTHnBBM0AAAAcQZtPSahBaJlMFPDf/qeEAHEB4U9kmHbud9rcqQAAABABn25qQr8AXRuQw+gJBxrZAAAAGEGbcEnhClJlMCG//qeEAEtUHV5chziygAAAACJBm5RJ4Q6JlMCG//6nhABP/dT7vN1iZuZZYmRyYno+kSbQAAAAE0GfskURPC//AC/KnnEWOaLIJCcAAAAPAZ/RdEK/AD4xh5Q0DNWpAAAAEAGf02pCvwA/iuDXHiraW+AAAAAaQZvVSahBaJlMCG///qeEADSurSCET/Lb6oEAAAARQZv5SeEKUmUwIb/+p4QAAScAAAAMQZ4XRTRML/8AALKBAAAAEAGeNnRCvwAqtlHfgA+3nsEAAAAQAZ44akK/ACq2Ud7PH289gAAAABpBmjpJqEFomUwIb//+p4QAUb0T/Ujo0hqiwQAAAB1BmlxJ4QpSZTBREsN//qeEAFR+NPyTTncujzi8+AAAABABnntqQr8AQ3NG80xVtLNBAAAAHUGafknhDomUwUTDf/6nhAA3fsH82l1A8OLIU6EXAAAAEAGenWpCvwAtdKN5pirabWAAAAAcQZqASeEPJlMFPDf//qeEACPfHT7VebVEZGQK3AAAABABnr9qQr8AHQCATrwBQCGBAAAAG0GaoUnhDyZTAh3//qmWAAd/2l/SafdIUTJvQAAAABJBmsVJ4Q8mUwId//6plgAAlYEAAAAMQZ7jRRE8L/8AALKAAAAAEAGfAnRCvwAHsUN3TsuzW4EAAAAPAZ8EakK/AAexQ3YZ6tCBAAAAE0GbCUmoQWiZTAh3//6plgAAlYEAAAAMQZ8nRREsL/8AALKBAAAAEAGfRnRCvwAHsUN3TsuzW4AAAAAPAZ9IakK/AAexQ3YZ6tCBAAAAKUGbTUmoQWyZTAhv//6nhAAOj7L6vgU19Qr8ClS2fgUzsDG3WMFT/a9tAAAAEEGfa0UVLC//AAiufucLMYgAAAAPAZ+KdEK/AAfEvQGSXVuAAAAAEAGfjGpCvwAL87cJuM+vVXkAAAAZQZuQSahBbJlMCG///qeEAA7QPCjj2S6OgQAAAA9Bn65FFSwr/wAMQRoHBMEAAAAPAZ/PakK/ABLbWu77viDAAAAAGkGb0UmoQWyZTAh3//6plgAHf9pfzukKYSfwAAAAEkGb9UnhClJlMCHf/qmWAACVgQAAAAxBnhNFNEwv/wAAsoAAAAAQAZ4ydEK/AAexQ3dOy7NbgAAAAA8BnjRqQr8AB7FDdhnq0IEAAAAcQZo4SahBaJlMCHf//qmWAATn5HQQzpZ0dTzHwAAAAA9BnlZFESwr/wAHxBXDl8EAAAANAZ53akK/AAfGvxhUvwAAABdBmnxJqEFsmUwIb//+p4QABf/YP8x6gAAAABNBnppFFSwv/wAFrtcZqZllyGpHAAAAEAGeuXRCvwAHl4YDJLf7LMAAAAAQAZ67akK/AAeZmDyYHr5ZgQAAAB9Bmr5JqEFsmUwUTDf//qeEAA7QPDixqh/vkcA/vuudAAAAEAGe3WpCvwAMQ6p5MD18NIAAAAAYQZrBSeEKUmUwIb/+p4QADuewevZnwRbfAAAAD0Ge/0U0TCv/AAxBGgcEwQAAAA0BnwBqQr8ADEWJFvgmAAAAGkGbAkmoQWiZTAhv//6nhAAOj77PqONCQ7jhAAAAIUGbJUnhClJlMCG//qeEAAl3x0+1Xm5pJKE19J0Ecs9baAAAABNBn0NFNEwr/wAHmCA+A/TNdzGBAAAAEAGfZGpCvwAE+a+c60MMMMEAAAAZQZtmSahBaJlMCG///qeEAAPP7B69mfBGhwAAABlBm4dJ4QpSZTAh3/6plgAB3/aXhagn9jmhAAAAKUGbq0nhDomUwId//qmWAALf76vfcPAprpOn4FKI8/ApmuWRxvnYfkZEAAAAEUGfyUURPC//AANgHoaOlZngAAAAEAGf6HRCvwAEmEAc7Y40/eEAAAAPAZ/qakK/AAR4NYF1/lXAAAAAHEGb70moQWiZTAh3//6plgACzfKSBw/2Lb3aOoAAAAAQQZ4NRREsL/8AA0wjjO6D4QAAABABnix0Qr8ABHXak8r8lO/RAAAADwGeLmpCvwAElta7vu/AwQAAABpBmjJJqEFsmUwId//+qZYAAtvyDNAHpL7aEAAAAA9BnlBFFSwr/wAEllcCo0AAAAANAZ5xakK/AASYNYeNGwAAABpBmnVJqEFsmUwId//+qZYAAu2llcZpf2xKwAAAAA9BnpNFFSwr/wAEtk3DxMAAAAAPAZ60akK/AAS4NYF1/lFBAAAAEkGauUmoQWyZTAhv//6nhAABJwAAABJBntdFFSwv/wADdORHvGrKr6kAAAAPAZ72dEK/AAS12UKTbJalAAAADwGe+GpCvwAEt2I8mB6+vwAAABpBmvtJqEFsmUwUTDf//qeEAAXX40/j+fjAvwAAAA8BnxpqQr8ABLZW6UaQ8yYAAAAdQZseSeEKUmUwIb/+p4QABWvbp5lliZHcr7nfsksAAAASQZ88RTRMK/8ABFdon6woS4OJAAAAEAGfXWpCvwAEdeaJkTStScAAAAAdQZtASahBaJlMFPDf/qeEAAVr3U/ary2fCjW6JssAAAAPAZ9/akK/AARWVulGkPNXAAAAGUGbYknhClJlMFLDf/6nhAADT+ysCE/zR0AAAAAQAZ+BakK/AAK9bW2GerSygQAAAB9Bm4RJ4Q6JlMFEw3/+p4QABSCxVTZAaaYZZ9+9z7b3AAAAEAGfo2pCvwAEF2iE3GfXsskAAAAaQZunSeEPJlMCGf/+nhAAHy9/d+Kxw5wexfkAAAAQQZ/FRRE8K/8ABpnVvWD7IQAAABABn+ZqQr8ABpmbmh5zzGCBAAAAGUGb6EmoQWiZTAhn//6eEAAef193ac3cXs4AAAAYQZoJSeEKUmUwIZ/+nhAAHc9/d2nN3F7mAAAAGkGaKknhDomUwIb//qeEAAdz4Df+vZnwRf+BAAAAG0GaS0nhDyZTAhv//qeEAAdH4DAJr17M+CMBwAAAABhBmm1J4Q8mUwURPDv//qmWAAJQiw3Rj+wAAAAPAZ6MakK/AAXTlYF1/kBBAAAAGUGakEnhDyZTAh3//qmWAAWT5BmgD0l9mdEAAAASQZ6uRRE8K/8ACO7PAhIx/AWBAAAADgGez2pCvwAI7s9dP1csAAAAHkGa0kmoQWiZTBTw7/6plgAFt+QZndJfhJJ0uQERaAAAABABnvFqQr8ACS5o3mmKttjBAAAAFkGa9knhClJlMCHf/qmWAAJj9HPygmAAAAARQZ8URTRML/8ABFfQEosGLIAAAAAPAZ8zdEK/AAX4A+KTbJZZAAAAEAGfNWpCvwAF+dU8mB6+iYAAAAATQZs6SahBaJlMCHf//qmWAACVgQAAABBBn1hFESwv/wAEV9BBU2ZPAAAAEAGfd3RCvwAF+AADJLf7RMAAAAAQAZ95akK/AAX52pbhs2swgQAAABlBm35JqEFsmUwId//+qZYAA6ntL+v67RoPAAAAEEGfnEUVLC//AARXP2bgknEAAAAPAZ+7dEK/AAYh5N55xm+BAAAAEAGfvWpCvwAF+I7c60MMH0AAAAAaQZuhSahBbJlMCHf//qmWAAJgUc60PV98xcAAAAAPQZ/fRRUsK/8AA8wK4e3BAAAADQGf4GpCvwADzV+MK24AAAAXQZvlSahBbJlMCHf//qmWAAGKgsrk7/EAAAAOQZ4DRRUsL/8AAc/99KAAAAAQAZ4idEK/AAPCob2XVfxfwQAAABABniRqQr8AA8KhvYrR92mBAAAAHEGaKUmoQWyZTAh3//6plgADjjqFkJNzT0Y/TvcAAAAQQZ5HRRUsL/8ABDaA5eR4IQAAABABnmZ0Qr8ABfrKu5DZUrLgAAAADwGeaGpCvwAF+BY2BypdgAAAABpBmm1JqEFsmUwId//+qZYAA5PtL+xbe7QsgQAAABBBnotFFSwv/wAENz9zhZ4IAAAADwGeqnRCvwAF+eTeecZ0gAAAABABnqxqQr8ABfmbmuPFW4ChAAAAE0GasUmoQWyZTAh3//6plgAAlYEAAAAMQZ7PRRUsL/8AALKBAAAAEAGe7nRCvwADwqG7p2XaEIAAAAAQAZ7wakK/AAPCob2K0fdpgAAAABNBmvVJqEFsmUwId//+qZYAAJWBAAAADEGfE0UVLC//AACygAAAABABnzJ0Qr8AA8Khu6dl2hCAAAAADwGfNGpCvwADwqG7DPVo6QAAABxBmzlJqEFsmUwId//+qZYAA446hZCTc09GP072AAAAEEGfV0UVLC//AAQ2gOXkeCEAAAAQAZ92dEK/AAX6yruQ2VKy4QAAAA8Bn3hqQr8ABfgWNgcqXYAAAAAbQZt7SahBbJlMFEw7//6plgADk+0v7Ft7tCyBAAAAEAGfmmpCvwAF+Zua48VbgKAAAAASQZufSeEKUmUwId/+qZYAAJWBAAAADEGfvUU0TC//AACygQAAABABn9x0Qr8AA8KhvZdV/F/AAAAADwGf3mpCvwADwqG7DPVo6QAAABNBm8NJqEFomUwId//+qZYAAJWBAAAADEGf4UURLC//AACygAAAABABngB0Qr8AA8KhvZdV/F/BAAAADwGeAmpCvwADwqG7DPVo6QAAACFBmgdJqEFsmUwId//+qZYAAoXuxcyyz59vu3O9abU9tO0AAAAVQZ4lRRUsL/8AAvytL10V8fu1ivDhAAAAEAGeRHRCvwAD4fIOa97l9/EAAAAQAZ5GakK/AAP4zB5MD194gQAAABxBmktJqEFsmUwId//+qZYAAoXvq++MKgWimIkuAAAAEEGeaUUVLC//AAL8q8b2EogAAAAPAZ6IdEK/AAP4X4uA/P3BAAAAEAGeimpCvwAEFzRvNMVbm0AAAAAjQZqPSahBbJlMCG///qeEAAVH3U/drX4L4FNdSHe9VV/Un/AAAAAVQZ6tRRUsL/8AAyPrljNuJwFUjyARAAAAEAGezHRCvwAEN9I31+lCgGEAAAAQAZ7OakK/AARXNG80xVuWwQAAAB5BmtJJqEFsmUwIb//+p4QABbPbp5lliZHcfdrS2NUAAAASQZ7wRRUsK/8ABJdob/Ybzs0CAAAADwGfEWpCvwAEl2I8mB6+xwAAABlBmxVJqEFsmUwIZ//+nhAAFqr3GhdN92AcAAAAD0GfM0UVLCv/AAS2TcPEwAAAAA8Bn1RqQr8ABLg1gXX+UUEAAAAZQZtWSahBbJlMCG///qeEAAX11aOtzbMTQAAAAB1Bm3hJ4QpSZTBRUsN//qeEAAlo+ZqbNuM3up8crQAAABABn5dqQr8AB5mYPJgevlmBAAAAGUGbmUnhDomUwIb//qeEAA55xn+q3zH4uOAAAAAaQZu8SeEPJlMCG//+p4QADtA8KOPV4P9WtI0AAAARQZ/aRRE8K/8ADEOrYJCVwDsAAAAOAZ/7akK/AAxDr4rgTu0AAAAYQZv/SahBaJlMCG///qeEAA7nsHtul10dAAAAEkGeHUURLCv/AAxBHogFMA6BwAAAAA4Bnj5qQr8ADEWJV1OoEwAAABlBmiJJqEFsmUwIZ//+nhAAWHgxz+HOb649AAAAEUGeQEUVLCv/ABJdnf9HJFZtAAAADgGeYWpCvwASXZ65r1m1AAAAHUGaZEmoQWyZTBRMM//+nhAA0shtb/DnN9WV3ONIAAAAEAGeg2pCvwAsVjxyv7cP6UEAAAAYQZqFSeEKUmUwIZ/+nhABRuDHP4c5vrPdAAAAG0GapknhDomUwIZ//p4QAfApxz+HPiApn6zNwQAAABpBmslL4QhDyRGCCgH8gH9h4AhX//44QAARcQAAAChBnudFETwr/wKvY+1BxN2qw0km5aqGByy49DZXi0QOTbK1p/eAssbAAAAAJAGfCGpCvwKvY+1BxN2qw0km5aqGByzNwoLwGITiTjK4gQrLZgAAC8htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAK8nRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACmptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAoVbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJ1XN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFoGN0dHMAAAAAAAAAsgAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAEAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAIAAAAAAIAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFyAAAABwAAAAUAAAAFAAAAB4AAAAdAAAAIgAAABkAAAAUAAAAFAAAAB4AAAAfAAAAFAAAABIAAAAgAAAAFAAAABwAAAAmAAAAFwAAABMAAAAUAAAAHgAAABUAAAAQAAAAFAAAABQAAAAeAAAAIQAAABQAAAAhAAAAFAAAACAAAAAUAAAAHwAAABYAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAALQAAABQAAAATAAAAFAAAAB0AAAATAAAAEwAAAB4AAAAWAAAAEAAAABQAAAATAAAAIAAAABMAAAARAAAAGwAAABcAAAAUAAAAFAAAACMAAAAUAAAAHAAAABMAAAARAAAAHgAAACUAAAAXAAAAFAAAAB0AAAAdAAAALQAAABUAAAAUAAAAEwAAACAAAAAUAAAAFAAAABMAAAAeAAAAEwAAABEAAAAeAAAAEwAAABMAAAAWAAAAFgAAABMAAAATAAAAHgAAABMAAAAhAAAAFgAAABQAAAAhAAAAEwAAAB0AAAAUAAAAIwAAABQAAAAeAAAAFAAAABQAAAAdAAAAHAAAAB4AAAAfAAAAHAAAABMAAAAdAAAAFgAAABIAAAAiAAAAFAAAABoAAAAVAAAAEwAAABQAAAAXAAAAFAAAABQAAAAUAAAAHQAAABQAAAATAAAAFAAAAB4AAAATAAAAEQAAABsAAAASAAAAFAAAABQAAAAgAAAAFAAAABQAAAATAAAAHgAAABQAAAATAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAATAAAAIAAAABQAAAAUAAAAEwAAAB8AAAAUAAAAFgAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAlAAAAGQAAABQAAAAUAAAAIAAAABQAAAATAAAAFAAAACcAAAAZAAAAFAAAABQAAAAiAAAAFgAAABMAAAAdAAAAEwAAABMAAAAdAAAAIQAAABQAAAAdAAAAHgAAABUAAAASAAAAHAAAABYAAAASAAAAHQAAABUAAAASAAAAIQAAABQAAAAcAAAAHwAAAB4AAAAsAAAAKAAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbcxwJwifY81",
        "colab_type": "code",
        "outputId": "1fe95238-34aa-4757-8e29-b4ff88668e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore0.mp4'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 22.5/10.0. Average score (12.5)\n",
            "Win/lose count 19.5/6.0. Average score (13.0)\n",
            "Win/lose count 24.0/5.0. Average score (15.0)\n",
            "Win/lose count 17.0/8.0. Average score (13.5)\n",
            "Win/lose count 26.0/9.0. Average score (14.2)\n",
            "Final score: 14.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGbRtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALxZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz6HlLQY0H4FLrPt8yyASH4nyznyz+UV3lZStToylPkRJtL1p2EDwHLxUKU3aLYc1jjUZ2zqWag6qob/yLS0NYhSD4lHKmPGUTkX/jHgDj4L0u4OX815o2HMagodDP1OpPpW9yyyyFBcuuvNnkZsdQpM451af+sYkA2OcyKnigqTMsaldi/c7JMiluJ3AqBHbkFtW8XfKIwv6wswUSoz7QQBN3EwT/NJMPeD2Mp2JTUCyz7Qk7C0nDLgw16s6RpLvcnmRwPOcr7xddoxgpu1A6nKNHfNAItdI7TSzqTNOzAyfDQik/SCpN7j9HglMGAMeoLvPjr5AEsNlnfSNpbS5flG4HTlf/TzgHWky7u7l2xY/CdUIr6qIbCFV8x14IHc0sv9yXWPlFZ6gzqAAZK568i5IgXfnrMEnfblSWT+qaY1aM4FtI/8bmK74+bu1Dcuy812JfsVVCdIJXv8ausZ9qX4RUmF5YB6CKxwRLxHKAwVjLFwLmkOSA9JapShURW05ye5lGKbGBTeVunEw20gQTmzM7wf/BGoRDBQ11KkhImBsXn+3qVaHLPZnwfjqqQAUMcL7ImyW+5DO+YxRoTKgkrsNLWRAr5e86AKrl8Fk+Ks/m6jYs0YatnDellzUGYYYTpXeYD4boGT5oRkzypohExo3wO9wDKOqfXQtdb0u9272GBOBtfcupml+6oAkL0r57YzvY1wdordJj85/WKL4o62p+v7mAOIz7OYmrzq51g5Z0+AOiB3e0owHiigmDwUhth9g0zP77EW9OAnV1zFNtSvzXFloRyWAiIJqyhjlAUGK6DyD2SE6NoYckjfAFVan6BwXFxL3sgXWCBCfmZqpEsEhT/vHg2mXuTzzOAFSDjuCkM38Np6ZjWjcNJhOaGqRQhoS3hvTf/yBqCeLPEppgVgScSXSooAMAI3AAAAFEGaIWxDf/6nhAE0dazbbPs+aJOAAAAAF0GaQjwhkymEN//+p4QBNfjpj/D6ttlDAAAAHUGaZknhDyZTAhn//p4QCKec33IV3cbDOdNim6b0AAAAEUGehEURPC//ARaf9Yy1b7u5AAAADwGeo3RCvwF/sq7vN2nlwQAAABABnqVqQr8A8oLznWhheIfBAAAAGUGap0moQWiZTAhn//6eEALp7pvoqVmvfk8AAAAqQZrJSeEKUmUwURLDP/6eEAHc9ff1I0ZdzgU19Qb8ClS0fgUzsCYP7VqLAAAAEAGe6GpCvwBkiZJpvpIONBAAAAAXQZrqSeEOiZTAhn/+nhABPfanIbFqNqUAAAAYQZsLSeEPJlMCGf/+nhAAzvr7+RIj6woOAAAAGEGbLEnhDyZTAhn//p4QAIN8Q/tkMfWFnwAAABlBm01J4Q8mUwIb//6nhAAWP3U/UcaEh0vBAAAAGUGbbknhDyZTAhv//qeEAA43sH+E4LdCpMEAAAAaQZuRSeEPJlMCGf/+nhAANzTViO/v2e7TOJEAAAASQZ+vRRE8K/8AC6WRC7DfS9W4AAAADwGf0GpCvwALpZEJwQOzYAAAABlBm9JJqEFomUwIb//+p4QADjewevZnwRbvAAAAH0Gb9EnhClJlMFESw3/+p4QAILaUz4SuZuY59dnfW0wAAAAQAZ4TakK/ABsHajlf24gPwAAAAB5BmhZJ4Q6JlMFEwz/+nhAAf339+p6P+cS7riPqjfUAAAAQAZ41akK/ABsCO3OtDC9aQAAAABlBmjdJ4Q8mUwIb//6nhAAVH3U/UcaEh1BBAAAAHUGaWUnhDyZTBRE8M//+nhAANP6+/psoXLrZq4HhAAAAEAGeeGpCvwALE1851oYX6UAAAAAbQZp6SeEPJlMCG//+p4QACHfI4BNevZnwRezBAAAAHUGam0nhDyZTAhv//qeEAAzpHMhAGWbmXQIT+8rgAAAAGUGavknhDyZTAhv//qeEAA0rq0dH3GzBcJEAAAAPQZ7cRRE8K/8ACstbhxBBAAAADwGe/WpCvwALFSjeqwBI4AAAABpBmv9JqEFomUwIb//+p4QAFG9E/1W+Y/FSQAAAAB1BmwFJ4QpSZTBREsN//qeEABSPjT8kz0/sFwELGQAAABABnyBqQr8AEFk+c6pmN+mAAAAAJkGbJUnhDomUwIb//qeEAEW+HPmWVbZT8CktA/gUy2jkgvPNyVeBAAAAFUGfQ0UVPC//ACoUCKUjpnLGJ7OA2AAAABABn2J0Qr8AJb6U8DplN/qBAAAAEAGfZGpCvwA4rPmN0OSDkLkAAAAZQZtmSahBaJlMCG///qeEAGvpE/1KQCqJwQAAAClBm4pJ4QpSZTAhn/6eEAGx9/fqXnZK7JleBTX1BlwKVLQuBTOwOUMowQAAABZBn6hFNEwv/wBDY+fRYozeWxiu9mFAAAAADwGfx3RCvwBdMsGDZjiTjwAAABABn8lqQr8AX5K2LDWGSRPhAAAAGkGby0moQWiZTAhv//6nhABLvjp9RxoSHFlAAAAAGEGb7UnhClJlMFESwz/+nhAAw8hjn8RWwAAAAA8BngxqQr8AKPSjeqwAw+EAAAAZQZoOSeEOiZTAhn/+nhABJVSnHPiApn60DwAAABhBmi9J4Q8mUwIb//6nhABzzjP9SkAqg8EAAAAYQZpQSeEPJlMCG//+p4QAtPon+pSAVNlAAAAAIEGac0nhDyZTAhn//p4QBwOuXXnkHz4QOU/f37DdiopIAAAAE0GekUURPCv/AVqx5unNbYSMSSUAAAAQAZ6yakK/AVqx45X9uHzbQAAAABlBmrRJqEFomUwIb//+p4QGKoY1NqW5cFGBAAAAF0Ga1UnhClJlMCG//qeEBiqGNTbZpVGBAAAAG0Ga+EnhDomUwIZ//p4QB1l2xoXTYpbT4qCY0AAAABFBnxZFETwr/wFjpRvNCwfZowAAAA4BnzdqQr8BY2xjJuSTRwAAABlBmzlJqEFomUwIb//+p4QBxu+zH+H1VjGDAAAAGUGbWknhClJlMCG//qeEAbLup+kQUJCyg4EAAAAZQZt+SeEOiZTAhn/+nhADy+vv6hoMc/l6mgAAABRBn5xFETwv/wCa+fAO+tJ+uRdpOwAAABABn7t0Qr8A0oB8Um2SqPmBAAAAEAGfvWpCvwDSuqeTA9e2xYAAAAAaQZu/SahBaJlMCG///qeEAa5on+p7+z5NccAAAAAYQZvCSeEKUmUwIZ/+nhAGh7psZcmyWMd1AAAAD0Gf4EU0TCv/AUhrcNZlQAAAAA8BngFqQr8BP+VgXX9+0kEAAAAZQZoDSahBaJlMCGf//p4QBkfObOt0DD7HpAAAABhBmiRJ4QpSZTAhn/6eEAYLzm+zMx9Xyk8AAAAZQZpFSeEOiZTAhv/+p4QA8vsH+E4LdCRdwQAAABhBmmZJ4Q8mUwIb//6nhACffHTH+H1bbTsAAAAaQZqJSeEPJlMCG//+p4QA7XsH+eUT/UucLF0AAAASQZ6nRRE8K/8Aw8fBG0tIk4qSAAAAEAGeyGpCvwDIs3NceKto9+AAAAASQZrNSahBaJlMCG///qeEAAEnAAAADEGe60URLC//AACygAAAABABnwp0Qr8AyNlXdX47v3/AAAAAEAGfDGpCvwB91DexWj7de0EAAAAZQZsOSahBbJlMCG///qeEAJ98dMf4fVttOwAAAB1BmzBJ4QpSZTBRUsN//qeEAOaDxNcaol+if5DseQAAABABn09qQr8AvtkQm4z69Nh4AAAAG0GbUUnhDomUwId//qmWALwSQk29ykgcP8FScAAAABFBm3VJ4Q8mUwIb//6nhAABJwAAAAxBn5NFETwv/wAAsoAAAAAQAZ+ydEK/AS7cd5gljaKWkAAAABABn7RqQr8BLnmiZdB08s2ZAAAAEkGbuUmoQWiZTAhn//6eEAAEfAAAABVBn9dFESwv/wDXsvjV1KR0lWeRRcEAAAAQAZ/2dEK/ASZ2pPK/JTZWUQAAABABn/hqQr8BLnmiZE0rNmzAAAAAGEGb+kmoQWyZTAhn//6eEAXHM45YuAnltQAAABdBmhtJ4QpSZTAhn/6eEAX8hx8C+VjHzAAAABdBmjxJ4Q6JlMCGf/6eEAY2px8C+VjHpQAAABlBml1J4Q8mUwIb//6nhASUQWbWs+z4GNGBAAAAHEGaf0nhDyZTBRE8N//+p4QEr7MfWluYYjCCi4AAAAAQAZ6eakK/Aeuy/VHzH4tgwAAAABtBmoBJ4Q8mUwIb//6nhAGR8jgE169mfAt6j4EAAAAbQZqhSeEPJlMCHf/+qZYAxHpdA4fC1BP4QEXAAAAAHUGaxUnhDyZTAh3//qmWAczxBJtOtL99YyPHt03pAAAAEUGe40URPC//AVFlLnlUdNe6AAAADwGfAnRCvwHGsVjCFWnVQQAAABABnwRqQr8BLs0bzTFW0crBAAAAEkGbCUmoQWiZTAhv//6nhAABJwAAAAxBnydFESwv/wAAsoEAAAAQAZ9GdEK/AMFnJxHZdlTugAAAAA8Bn0hqQr8AwWcm6z1Z6Z8AAAAaQZtMSahBbJlMCG///qeEAPGDwp1nT7ra6YEAAAARQZ9qRRUsK/8AyLq2CQlb7XEAAAAOAZ+LakK/AMi6+K4ElcQAAAAaQZuNSahBbJlMCHf//qmWAHzHT8pox+tJP8EAAAAbQZuxSeEKUmUwIb/+p4QBrgrVMf6pvewfq8q5AAAAHUGfz0U0TC//AO0nUFuA74hC7//EIL4n//s1ghr5AAAADwGf7nRCvwDXyH43qCNZnwAAABABn/BqQr8BSLIhNxn16aoIAAAAGUGb9EmoQWiZTAhv//6nhAHBDwp1nT7OMccAAAAPQZ4SRREsK/8BUWtw1mLAAAAADQGeM2pCvwFR5SLesxYAAAAcQZo3SahBbJlMCG///qeEBY9E/09rVQIT+jyHgQAAABJBnlVFFSwr/wILY6lbPX/ZCYAAAAAOAZ52akK/Agtjvk90pTUAAAAZQZp6SahBbJlMCG///qeEBib3+emF9ETDFwAAAA9BnphFFSwr/wIeRoEUd0AAAAANAZ65akK/Ah9iRbijuwAAAB1Bmr1JqEFsmUwIZ//+nhAZXg/KPqFfewIx9QoZUAAAABFBnttFFSwr/wIyzc1x7CR7LwAAAA4BnvxqQr8CMkhnjyrsvQAAABlBmv5JqEFsmUwIZ//+nhAHG6+/i8VmvXN+AAAAGEGbH0nhClJlMCGf/p4QBDBDj+eC/khlnAAAABhBmyBJ4Q6JlMCG//6nhAEcHzHkYn+W2V8AAAAXQZtBSeEPJlMCG//+p4QBJB8xyuG22VUAAAAZQZtiSeEPJlMCHf/+qZYBFBMN0VSFHyErYQAAAB1Bm4ZJ4Q8mUwId//6plgR4LK4/j9XjaXUdWcjfgAAAABRBn6RFETwv/wHDH6hWzwKMUnACZwAAABABn8N0Qr8CX2KxbGwSXjAhAAAAEAGfxWpCvwJID+NXf8/x+4EAAAAZQZvKSahBaJlMCG///qeEAiJ9K9b3U+GzZwAAABBBn+hFESwv/wEOz9m4IDJwAAAADwGeB3RCvwDnl+LgPy0TQAAAABABnglqQr8BdbCPJgevbN6BAAAAHkGaDUmoQWyZTAhv//6nhAIp46fZjTo5lliZHdHbAgAAABJBnitFFSwr/wF1blCpaJf7Y2UAAAAQAZ5MakK/APgzB5LmfJKRgQAAABlBmk5JqEFsmUwIb//+p4QBPB8x5GJ/lJk3AAAAG0Gab0nhClJlMCG//qeEAT35HAP7+VYZCh09IQAAACxBmpNJ4Q6JlMCG//6nhADN+wf5a6XL4hGLfx7dPApr6f25liV23ApnYDhtgAAAABVBnrFFETwv/wB5f2V4pumcV+bJ924AAAAQAZ7QdEK/AKgnKpLGwH6KwQAAABABntJqQr8ARWT5zrQwvJzAAAAAHkGa1kmoQWiZTAhn//6eEADT+vv6FdHS3py+YatGDgAAABNBnvRFESwr/wAsTboqs80zXtlBAAAAEAGfFWpCvwAcUImab6SDmXAAAAAZQZsXSahBbJlMCG///qeEABdAUFeXIc6PgQAAAB1BmzlJ4QpSZTBRUsM//p4QADo+vv6bKFy62at+kQAAAA8Bn1hqQr8ADEEtKkUCVx4AAAAYQZtaSeEOiZTAhv/+p4QACXfRzQVrMpvfAAAAGUGbe0nhDyZTAhv//qeEAAk3x0+o40JD20AAAAAeQZudSeEPJlMFETw3//6nhAAF/9g/y10g1bMUJFHXAAAAEAGfvGpCvwAE1ldFVnH4K3EAAAAYQZugSeEPJlMCGf/+nhAAFq4Mc/hzm+zTAAAAEUGf3kURPCv/AAS3Z3/RyRalAAAADgGf/2pCvwAEt2eua9qVAAAAGkGb4kmoQWiZTBTwz/6eEAAWz4nfHXecb0vuAAAAEAGeAWpCvwAEtk+c60MMNkEAAAAaQZoDSeEKUmUwIZ/+nhAADjex8GP3ac3cYuQAAAAYQZokSeEOiZTAhn/+nhAAFY4Mc/hzm+zpAAAAGEGaRUnhDyZTAhn//p4QABYa9xoXTfdgRQAAABdBmmZJ4Q8mUwIb//6nhAAFzxWjqobcawAAAB1BmohJ4Q8mUwURPDf//qeEAAj3x0zQCzbePN4k6QAAABABnqdqQr8ABz+cNe80rR3AAAAAGEGaqUnhDyZTAhv//qeEAAi3x0x/h9W4JwAAABhBmsxJ4Q8mUwIb//6nhAAId8dMf4fVuDEAAAASQZ7qRRE8K/8ABuiPRAKYB1sgAAAADgGfC2pCvwAG6sSrqdSHAAAAHEGbDkmoQWiZTBTw3/6nhAAIN8dPuZGFsxQjnzkAAAAQAZ8takK/AAbAjtzrQwwUQQAAACBBmzJJ4QpSZTAhv/6nhAAMn6w3MssTI2aJ/rDfPPNcWQAAABVBn1BFNEwv/wAHbTZDQxP3awql2DYAAAAQAZ9vdEK/AAZyTQifFmKcmAAAABABn3FqQr8ACj2EeTA9fFmBAAAAGkGbc0moQWiZTAhv//6nhAAM26tIIRP8t7CAAAAAF0GblknhClJlMCGf/p4QADJ+vvBBfTEwAAAAEkGftEU0TCv/AAqDYAgFMA6OQQAAAA4Bn9VqQr8ACocpV1OoSwAAABlBm9dJqEFomUwIb//+p4QADJ+wevZnwRcbAAAAGEGb+knhClJlMCGf/p4QAC/+/u7Tm7i7HQAAAA9BnhhFNEwr/wAJ81uHF8AAAAANAZ45akK/AAn3KRb4vwAAABlBmjtJqEFomUwIZ//+nhAALr8Ts63QMkcMAAAAG0GaXEnhClJlMCG//qeEABHUAWbbaAwCa/u/0QAAABhBmn1J4Q6JlMCG//6nhAAbmkT/UpAK18EAAAAfQZqfSeEPJlMFETw3//6nhAAsOK1TH8uAZkGpg/kJUAAAAA8Bnr5qQr8AI7sR5MD17p8AAAAbQZqiSeEPJlMCG//+p4QAQ1AFmz4P88cH3x8xAAAAEEGewEURPCv/ADdEeh2SS0gAAAAPAZ7hakK/ADa5ybrPVnttAAAAG0Ga5kmoQWiZTAhn//6eEAEG+If4xu6jcSr5gAAAABBBnwRFESwv/wAo9AitKKZ5AAAADwGfI3RCvwBWegHQnJee4QAAABABnyVqQr8AN0TJNN9JByHxAAAAGUGbJ0moQWyZTAhn//6eEACx+6b6KlZr4W8AAAAcQZtJS+EIQpSRGCCgH8gH9h4BRUsK//44QAARcAAAACQBn2hqQr8Cr2PtQcTdqsNJJuWqhgcstbvNLBZGpE19O4H+13MAAAsQbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAACjp0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAmybWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAJXW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACR1zdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABOhjdHRzAAAAAAAAAJsAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAABQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAMAAAQAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAAEAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAQAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAUAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAABAAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAwAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFpgAAABgAAAAbAAAAIQAAABUAAAATAAAAFAAAAB0AAAAuAAAAFAAAABsAAAAcAAAAHAAAAB0AAAAdAAAAHgAAABYAAAATAAAAHQAAACMAAAAUAAAAIgAAABQAAAAdAAAAIQAAABQAAAAfAAAAIQAAAB0AAAATAAAAEwAAAB4AAAAhAAAAFAAAACoAAAAZAAAAFAAAABQAAAAdAAAALQAAABoAAAATAAAAFAAAAB4AAAAcAAAAEwAAAB0AAAAcAAAAHAAAACQAAAAXAAAAFAAAAB0AAAAbAAAAHwAAABUAAAASAAAAHQAAAB0AAAAdAAAAGAAAABQAAAAUAAAAHgAAABwAAAATAAAAEwAAAB0AAAAcAAAAHQAAABwAAAAeAAAAFgAAABQAAAAWAAAAEAAAABQAAAAUAAAAHQAAACEAAAAUAAAAHwAAABUAAAAQAAAAFAAAABQAAAAWAAAAGQAAABQAAAAUAAAAHAAAABsAAAAbAAAAHQAAACAAAAAUAAAAHwAAAB8AAAAhAAAAFQAAABMAAAAUAAAAFgAAABAAAAAUAAAAEwAAAB4AAAAVAAAAEgAAAB4AAAAfAAAAIQAAABMAAAAUAAAAHQAAABMAAAARAAAAIAAAABYAAAASAAAAHQAAABMAAAARAAAAIQAAABUAAAASAAAAHQAAABwAAAAcAAAAGwAAAB0AAAAhAAAAGAAAABQAAAAUAAAAHQAAABQAAAATAAAAFAAAACIAAAAWAAAAFAAAAB0AAAAfAAAAMAAAABkAAAAUAAAAFAAAACIAAAAXAAAAFAAAAB0AAAAhAAAAEwAAABwAAAAdAAAAIgAAABQAAAAcAAAAFQAAABIAAAAeAAAAFAAAAB4AAAAcAAAAHAAAABsAAAAhAAAAFAAAABwAAAAcAAAAFgAAABIAAAAgAAAAFAAAACQAAAAZAAAAFAAAABQAAAAeAAAAGwAAABYAAAASAAAAHQAAABwAAAATAAAAEQAAAB0AAAAfAAAAHAAAACMAAAATAAAAHwAAABQAAAATAAAAHwAAABQAAAATAAAAFAAAAB0AAAAgAAAAKAAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWxIdNOJfY84",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB0htU1NfY86",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVJNaIE-fY8-",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}